{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examplifying the use of the IAE code\n",
    "### This is a simple application of the IAE code on 1D Gaussian-shaped signals\n",
    "### It features:\n",
    "    - An example of the learning stage, showing how to choose the main hyperparameters\n",
    "    - An illustration of the way the learnt model can be used to regularized a simple inverse problem (here denoising)\n",
    "other examples to come soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "PATH ='../codes'\n",
    "sys.path.insert(1,PATH)\n",
    "\n",
    "import IAE_JAX as mld\n",
    "import DataGeneration as dg\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create the data\n",
    "\n",
    "train_samp_number = 100\n",
    "validation_samp_number = 100\n",
    "test_samp_number = 100\n",
    "t_length = 50\n",
    "\n",
    "Output = dg.GaussianShaped(t_length=t_length, t_start=0, pmin=15, pmax=35, train_samp_number=train_samp_number,\n",
    "                           validation_samp_number=validation_samp_number, test_samp_number=test_samp_number, \n",
    "                           law='linear')\n",
    "\n",
    "AnchorPoints = Output[\"Psi\"][[0,1],:] # Define the anchor points\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(AnchorPoints[0:2,:].T,'k--',lw=8,alpha=0.5,label='Anchor points')\n",
    "plt.plot(Output[\"X_train\"][0:10,:].T,lw = 4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1 # Regularization parameter\n",
    "step_size = 1e-3 # gradient step size\n",
    "niter = 5000 # number of iterations or epochs\n",
    "\n",
    "vNL = [2,3,4]\n",
    "\n",
    "for NL in vNL:  # Learning with various numbers of layers\n",
    "\n",
    "    if NL == 2:\n",
    "        out0 = None # out0 is a first guess model\n",
    "        \n",
    "    fname = 'model_L'+np.str(NL) # filename of the saved model (pickle file)\n",
    "    NSize = t_length*np.ones((NL+1,),dtype='int') # shape of the network\n",
    "    LearnFunc = mld.IAE(fname=fname, Model=out0, simplex=True,\n",
    "                                   AnchorPoints=AnchorPoints, NSize=NSize, step_size=step_size, reg_parameter=mu, \n",
    "                                   niter=niter, active_forward='lRelu', active_backward='lRelu', reg_inv=1e-8, \n",
    "                                   verb=True)   # Defines the learning class\n",
    "    learnt_params, outval = LearnFunc.learning_stage(Output[\"X_train\"], XValidation= Output[\"X_valid\"], batch_size=100)  # learning stage\n",
    "    out0 = mld.load_model(fname)\n",
    "    plt.figure(figsize=[12,10])\n",
    "    plt.loglog(outval[\"total_cost\"], lw=8, alpha=0.25)\n",
    "    plt.loglog(outval[\"samp_cost\"], '.-', lw=4, alpha=0.25)\n",
    "    plt.loglog(outval[\"trans_cost\"],'--', lw=4, alpha=0.25)\n",
    "    plt.legend([\"total\",\"sample-based\",\"tf-based\"])\n",
    "    plt.title('Optim adam - NLayersns {:.2e}'.format(NL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection onto the barycentric span and robustness to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='model_L4' # MODEL\n",
    "ampp = 1. # AMPLITUDE\n",
    "noise_level = 0.01 # NOISE LEVEL\n",
    "Xb = ampp*Output[\"X_test\"][0:1,:] + noise_level*np.random.randn(1,50) # ADD SOME NOISE\n",
    "\n",
    "model = mld.load_model(fname)\n",
    "LearnFunc = mld.IAE(Model = model) # niter is the number of iterations\n",
    "\n",
    "rec_clean = LearnFunc.barycentric_span_projection(Xb,niter=1000)[\"XRec\"].squeeze() # projection onto the barycentric span\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,10])\n",
    "plt.plot(Xb.squeeze(),lw=10,alpha=0.25,label=\"noisy measurement\")\n",
    "plt.plot(ampp*Output[\"X_test\"][0:1,:].squeeze(),'r--',lw=6,alpha=0.75,label='input signal')\n",
    "plt.plot(rec_clean,'k',lw=3,alpha=0.8,label=\"clean projection\")\n",
    "plt.plot(ampp*Output[\"X_test\"][0:1,:].squeeze()-rec_clean,'g--',lw=4,alpha=0.75,label=\"residual error\")\n",
    "plt.title('Reconstruction - '+fname)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
